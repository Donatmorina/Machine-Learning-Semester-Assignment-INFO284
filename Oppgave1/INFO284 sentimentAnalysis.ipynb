{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK datasets\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "\n",
    "def preprocess_data(filepath=\"Hotel_Reviews.csv\", test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Loads, cleans, and splits the data.\n",
    "    \"\"\"\n",
    "    # Read data\n",
    "    df = pd.read_csv(filepath)\n",
    "\n",
    "    # Combine positive and negative reviews into one column\n",
    "    # Casting to string to avoid issues in case of missing or non-string data\n",
    "    df[\"Positive_Review\"] = df[\"Positive_Review\"].astype(str)\n",
    "    df[\"Negative_Review\"] = df[\"Negative_Review\"].astype(str)\n",
    "    df[\"reviews\"] = df[\"Positive_Review\"] + \" \" + df[\"Negative_Review\"]\n",
    "    \n",
    "    # Label reviews: 0 for good (score > 5), 1 for bad reviews (score <= 5)\n",
    "    df[\"Bad_reviews\"] = df[\"Reviewer_Score\"].apply(lambda x: 0 if x > 5 else 1)\n",
    "    \n",
    "    # Keep only the relevant columns\n",
    "    df = df[[\"reviews\", \"Bad_reviews\"]]\n",
    "    \n",
    "    # Remove placeholders in combined reviews\n",
    "    df[\"reviews\"] = (\n",
    "        df[\"reviews\"]\n",
    "        .str.replace(\"No Negative\", \"\", regex=False)\n",
    "        .str.replace(\"No Positive\", \"\", regex=False)\n",
    "    )\n",
    "    \n",
    "    # Remove missing and duplicate reviews\n",
    "    df.dropna(subset=[\"reviews\"], inplace=True)\n",
    "    df.drop_duplicates(subset=[\"reviews\"], inplace=True)\n",
    "    \n",
    "    # For EDA: Print distribution and review length statistics\n",
    "    print(\"Sentiment Label Distribution:\")\n",
    "    print(df[\"Bad_reviews\"].value_counts())\n",
    "    \n",
    "    df[\"review_length\"] = df[\"reviews\"].apply(len)\n",
    "    print(\"\\nReview Length Statistics:\")\n",
    "    print(df[\"review_length\"].describe())\n",
    "\n",
    "    def clean_text(text):\n",
    "        \"\"\"Cleans and lemmatizes text.\"\"\"\n",
    "        # Keep certain negation words\n",
    "        keep_words = {\"not\", \"no\", \"never\"}\n",
    "        \n",
    "        # Lowercase and remove non-alphabetic characters\n",
    "        text = text.lower()\n",
    "        text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "        \n",
    "        # Tokenize\n",
    "        words = word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords but preserve negation words\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        filtered_words = [w for w in words if (w not in stop_words) or (w in keep_words)]\n",
    "        \n",
    "        # Lemmatize\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
    "        \n",
    "        return \" \".join(lemmatized_words)\n",
    "    \n",
    "    # Clean the reviews\n",
    "    df[\"Reviews_clean\"] = df[\"reviews\"].apply(clean_text)\n",
    "    \n",
    "    # Split into train and test\n",
    "    train_df, test_df = train_test_split(\n",
    "        df, \n",
    "        test_size=test_size, \n",
    "        random_state=random_state, \n",
    "        stratify=df[\"Bad_reviews\"]\n",
    "    )\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "train_df, test_df = preprocess_data(\"Hotel_Reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Logistic Regression (TF-IDF) Evaluation ---\n",
      "Accuracy:  0.9487225710823344\n",
      "Precision: 0.6847555923777962\n",
      "Recall:    0.2749500998003992\n",
      "F1 Score:  0.3923569902682174\n",
      "Confusion Matrix:\n",
      "[[93076   761]\n",
      " [ 4359  1653]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97     93837\n",
      "           1       0.68      0.27      0.39      6012\n",
      "\n",
      "    accuracy                           0.95     99849\n",
      "   macro avg       0.82      0.63      0.68     99849\n",
      "weighted avg       0.94      0.95      0.94     99849\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Part A: TF-IDF Based Models (Logistic Regression, SVM, Random Forest)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Rebuild TF-IDF features using the cleaned reviews\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(train_df[\"Reviews_clean\"])\n",
    "X_test_tfidf = tfidf_vectorizer.transform(test_df[\"Reviews_clean\"])\n",
    "y_train = train_df[\"Bad_reviews\"]\n",
    "y_test = test_df[\"Bad_reviews\"]\n",
    "\n",
    "# Define a function for evaluation\n",
    "def evaluate_model(model, X_test, y_test, model_name=\"Model\"):\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"--- {model_name} Evaluation ---\")\n",
    "    print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "    print(\"Recall:   \", recall_score(y_test, y_pred))\n",
    "    print(\"F1 Score: \", f1_score(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\n\")\n",
    "\n",
    "# 1. Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train_tfidf, y_train)\n",
    "evaluate_model(lr_model, X_test_tfidf, y_test, \"Logistic Regression (TF-IDF)\")\n",
    "\n",
    "# 2. Support Vector Machine (SVM)\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train_tfidf, y_train)\n",
    "evaluate_model(svm_model, X_test_tfidf, y_test, \"SVM (TF-IDF)\")\n",
    "\n",
    "# 3. Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_tfidf, y_train)\n",
    "evaluate_model(rf_model, X_test_tfidf, y_test, \"Random Forest (TF-IDF)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Part B: LSTM Model Using Word Embeddings\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# For the LSTM, work with the cleaned text directly.\n",
    "# Set hyperparameters for tokenization and sequence processing.\n",
    "max_vocab = 10000\n",
    "max_len = 100  # maximum review length in terms of tokens\n",
    "embedding_dim = 100\n",
    "\n",
    "# Tokenize the text\n",
    "tokenizer = Tokenizer(num_words=max_vocab, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(train_df[\"Reviews_clean\"])\n",
    "\n",
    "# Convert texts to sequences and pad them\n",
    "X_train_seq = tokenizer.texts_to_sequences(train_df[\"Reviews_clean\"])\n",
    "X_test_seq = tokenizer.texts_to_sequences(test_df[\"Reviews_clean\"])\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post', truncating='post')\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "# Build the LSTM model\n",
    "lstm_model = Sequential([\n",
    "    Embedding(input_dim=max_vocab, output_dim=embedding_dim, input_length=max_len),\n",
    "    LSTM(64, return_sequences=False),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "lstm_model.summary()\n",
    "\n",
    "# Train the LSTM model\n",
    "lstm_model.fit(X_train_pad, y_train, epochs=5, batch_size=32, validation_split=0.1, verbose=1)\n",
    "\n",
    "# Evaluate the LSTM model\n",
    "lstm_loss, lstm_acc = lstm_model.evaluate(X_test_pad, y_test, verbose=0)\n",
    "print(\"--- LSTM (Word Embeddings) Evaluation ---\")\n",
    "print(\"Accuracy: \", lstm_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation \n",
    "y_pred_lstm_prob = lstm_model.predict(X_test_pad)\n",
    "y_pred_lstm = (y_pred_lstm_prob > 0.5).astype(int)\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_lstm))\n",
    "print(\"Recall:   \", recall_score(y_test, y_pred_lstm))\n",
    "print(\"F1 Score: \", f1_score(y_test, y_pred_lstm))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_lstm))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_lstm))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
