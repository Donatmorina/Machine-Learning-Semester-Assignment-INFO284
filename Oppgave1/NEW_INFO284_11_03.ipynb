{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt_tab', quiet=True) # Download Punkt tab \n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preprocessing Function\n",
    "def preprocess_data(filepath=\"Hotel_Reviews.csv\", test_size=0.2, random_state=42):\n",
    "    df = pd.read_csv(filepath)\n",
    "    df[\"Positive_Review\"] = df[\"Positive_Review\"].astype(str)\n",
    "    df[\"Negative_Review\"] = df[\"Negative_Review\"].astype(str)\n",
    "    df[\"reviews\"] = df[\"Positive_Review\"] + \" \" + df[\"Negative_Review\"]\n",
    "    df[\"Bad_reviews\"] = df[\"Reviewer_Score\"].apply(lambda x: 0 if x > 5 else 1)\n",
    "    df = df[[\"reviews\", \"Bad_reviews\"]]\n",
    "    df[\"reviews\"] = (\n",
    "        df[\"reviews\"]\n",
    "        .str.replace(\"No Negative\", \"\", regex=False)\n",
    "        .str.replace(\"No Positive\", \"\", regex=False)\n",
    "    )\n",
    "    df.dropna(subset=[\"reviews\"], inplace=True)\n",
    "    df.drop_duplicates(subset=[\"reviews\"], inplace=True)\n",
    "    \n",
    "    def clean_text(text):\n",
    "        keep_words = {\"not\", \"no\", \"never\"}\n",
    "        text = text.lower()\n",
    "        text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "        words = word_tokenize(text)\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        filtered_words = [w for w in words if (w not in stop_words) or (w in keep_words)]\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
    "        return \" \".join(lemmatized_words)\n",
    "    \n",
    "    df[\"Reviews_clean\"] = df[\"reviews\"].apply(clean_text)\n",
    "    train_df, test_df = train_test_split(df, test_size=test_size, random_state=random_state, stratify=df[\"Bad_reviews\"])\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load and Preprocess Data\n",
    "train_df, test_df = preprocess_data(\"Hotel_Reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TF-IDF Vectorization and Logistic Regression\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(train_df[\"Reviews_clean\"])\n",
    "X_test_tfidf = tfidf_vectorizer.transform(test_df[\"Reviews_clean\"])\n",
    "y_train = train_df[\"Bad_reviews\"]\n",
    "y_test = test_df[\"Bad_reviews\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read data\n",
    "df = pd.read_csv(\"Hotel_Reviews.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train_tfidf, y_train)\n",
    "evaluate_model(lr_model, X_test_tfidf, y_test, \"Logistic Regression (TF-IDF)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train and Evaluate Naive Bayes Model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "evaluate_model(nb_model, X_test_tfidf, y_test, \"Naive Bayes (TF-IDF)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train and Evaluate Decision Tree Model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train_tfidf, y_train)\n",
    "evaluate_model(dt_model, X_test_tfidf, y_test, \"Decision Tree (TF-IDF)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LSTM Model\n",
    "max_vocab = 10000\n",
    "max_len = 100\n",
    "embedding_dim = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_vocab, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(train_df[\"Reviews_clean\"])\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(train_df[\"Reviews_clean\"])\n",
    "X_test_seq = tokenizer.texts_to_sequences(test_df[\"Reviews_clean\"])\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post', truncating='post')\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Build and Train LSTM Model\n",
    "lstm_model = Sequential([\n",
    "    Embedding(input_dim=max_vocab, output_dim=embedding_dim, input_length=max_len),\n",
    "    LSTM(64, return_sequences=False),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluate LSTM Model\n",
    "lstm_loss, lstm_acc = lstm_model.evaluate(X_test_pad, y_test, verbose=0)\n",
    "print(\"--- LSTM (Word Embeddings) Evaluation ---\")\n",
    "print(\"Accuracy: \", lstm_acc)\n",
    "y_pred_lstm_prob = lstm_model.predict(X_test_pad)\n",
    "y_pred_lstm = (y_pred_lstm_prob > 0.5).astype(int)\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_lstm))\n",
    "print(\"Recall:   \", recall_score(y_test, y_pred_lstm))\n",
    "print(\"F1 Score: \", f1_score(y_test, y_pred_lstm))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_lstm))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_lstm))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
