{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libaries\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>Bad_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Only the park outside of the hotel was beauti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No real complaints the hotel was great great ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Location was good and staff were ok It is cut...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Great location in nice surroundings the bar a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazing location and building Romantic settin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  Bad_reviews\n",
       "0   Only the park outside of the hotel was beauti...            1\n",
       "1   No real complaints the hotel was great great ...            0\n",
       "2   Location was good and staff were ok It is cut...            0\n",
       "3   Great location in nice surroundings the bar a...            1\n",
       "4   Amazing location and building Romantic settin...            0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Prepearing the data\n",
    "\n",
    "# Read data\n",
    "data_frame = pd.read_csv(\"Hotel_Reviews.csv\")\n",
    "\n",
    "# All the postive and negative reviews \n",
    "data_frame[\"reviews\"] = data_frame[\"Positive_Review\"] + data_frame[\"Negative_Review\"]\n",
    "\n",
    "# Find all bad reviews and lable them 1 if it is bad and 0 if it is good\n",
    "data_frame[\"Bad_reviews\"] = data_frame[\"Reviewer_Score\"].apply(lambda x: 0 if x > 5 else 1)\n",
    "\n",
    "# New dataframe\n",
    "data_frame = data_frame[[\"reviews\", \"Bad_reviews\"]]\n",
    "\n",
    "# Drop NaN values\n",
    "data_frame[\"reviews\"] = data_frame[\"reviews\"].apply(lambda x: x.replace(\"No Negative\", \"\"))\n",
    "data_frame[\"reviews\"] = data_frame[\"reviews\"].apply(lambda x: x.replace(\"No Positive\", \"\"))\n",
    "\n",
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sampling the data \n",
    "\n",
    "# We sample the data in order to speed up computation\n",
    "data_frame = data_frame.sample(frac = 0.1, replace = False, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt_tab')\n",
    "\n",
    "def clean_text(text: str):\n",
    "    # Words to keep because they might be valuable for sentiment analysis\n",
    "    keep_words = {\"not\", \"no\", \"never\"}\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special characters using regex\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    \n",
    "    # Tokenize the text into words\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords (except the ones in keep_words)\n",
    "    english_stop_words = set(stopwords.words(\"english\"))\n",
    "    filtered_words = [word for word in words if word not in english_stop_words or word in keep_words]\n",
    "    \n",
    "    # Join the words back into a single string\n",
    "    cleaned_text = \" \".join(filtered_words)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "# Clean text in the DataFrame\n",
    "data_frame[\"Reviews_clean\"] = data_frame[\"reviews\"].apply(clean_text)\n",
    "data_frame[\"Reviews_clean\"] = pd.DataFrame(data_frame[\"Reviews_clean\"])\n",
    "\n",
    "# Display the first few rows\n",
    "print(data_frame[[\"Reviews_clean\", \"Bad_reviews\"]].head())\n",
    "\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt_tab')\n",
    "\n",
    "def clean_text(text: str):\n",
    "    # Words to keep because they might be valuable for sentiment analysis\n",
    "    keep_words = {\"not\", \"no\", \"never\"}\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special characters using regex\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    \n",
    "    # Tokenize the text into words\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords (except the ones in keep_words)\n",
    "    english_stop_words = set(stopwords.words(\"english\"))\n",
    "    filtered_words = [word for word in words if word not in english_stop_words or word in keep_words]\n",
    "    \n",
    "    # Join the words back into a single string\n",
    "    cleaned_text = \" \".join(filtered_words)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "# Clean text in the DataFrame\n",
    "data_frame[\"Reviews_clean\"] = data_frame[\"reviews\"].apply(clean_text)\n",
    "data_frame[\"Reviews_clean\"] = pd.DataFrame(data_frame[\"Reviews_clean\"])\n",
    "\n",
    "# Display the first few rows\n",
    "print(data_frame[[\"Reviews_clean\", \"Bad_reviews\"]].head())\n",
    "\n",
    "\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
